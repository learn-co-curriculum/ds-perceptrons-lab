{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: building your first neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it to your first lab! In this lab, you'll practice everything you have learned during the lecture. We know there is quite a bit of math involved, but don't worry! Using Python and trying things out yourself will actually make a lot of things much more clear! Before we start, let's load some necessary libraries so we can import our data.\n",
    "\n",
    "Run the cell below to import what we'll need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll get a bunch of images, and the purpose is to correctly classify these images as \"Santa\", meaning that Santa is present on the image or \"not Santa\" meaning that something else is in the images. \n",
    "\n",
    "If you have a look at this github repository, you'll notice that the images are simply stored in .jpeg-files and stored under the folder `/data`. Luckily, `keras` had great modules that make importing images stored in this type of format easy. We'll do this for you in the code below.\n",
    "\n",
    "The images in the `/data` folder have various resultions. We will reshape them so they are all have 64 x 64 pixels.\n",
    "\n",
    "Run the cell below to build generators that batch our data and their corresponding labels, so that we can read them in effectively during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory path\n",
    "train_data_dir = 'data/train'\n",
    "test_data_dir = 'data/validation'\n",
    "\n",
    "# get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(64, 64), batch_size=132)\n",
    "\n",
    "# get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(64, 64), batch_size=790)\n",
    "\n",
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inspecting and preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Look at some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have 4 numpy arrays now: `train_images`, `train_labels`, `test_images`, `test_labels`. We'll need to make some changes to the data in order to make them workable, but before we do anything else, let's have a look at some of the images we loaded. We'll look at some images in train_images. You can use `array_to_img()` from `keras.processing.image` on any `train_image` (select any train_image by doing `train_image[index]` to look at it.\n",
    "\n",
    "Run the cells below to examine some sample images from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_to_img(train_images[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 The shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `np.shape()` to look at what these numpy arrays look like.* training images\n",
    "\n",
    "In the cell below, print out the `.shape` of our:\n",
    "* training images\n",
    "* training labels\n",
    "* testing images\n",
    "* testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1  `train_images` and `test_images`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with `train_images`. From the lecture, you might remember that the expected input shape is $n$ x $l$. How does this relate to what we see here?\n",
    "\n",
    "$l$ denotes the number of observations, or the number of images. The number of images in `train_images` is 790. $n$ is the number of elements in the feature vector for each image, or put differently, $n$ is the number of rows when unrowing the 3 (RGB) 64 x 64 matrices. \n",
    "\n",
    "So, translated to this example, we need to transform our `(790, 64, 64, 3)` matrix to a `(64*64*3, 790)` matrix! \n",
    "\n",
    "Run the cell below to reshape and transpose our training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_unrow = train_images.reshape(790, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `np.shape` on the newly created `train_img_unrow` to verify that the shape is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Expected Output (12288, 790)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's transform test_images in a similar way. Note that the dimensions are different here! Where we needed to have a matrix shape if $ n$ x $l $ for `train_images`, for `test_images`, we need to get to a shape of $ n$ x $m$. What is $m$ here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 132\n",
    "test_img_unrow = test_images.reshape(m, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `np.shape` to check the shape our `test_img_unrow` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Expected Output (12288, 132)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2  `train_labels` and `test_labels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, you noticed that `train_labels` and `test_labels` have shapes of $(790, 2)$ and $(132, 2)$ respectively. In the lecture, we expected $1$ x $l$ and $1$ x $m$.\n",
    "\n",
    "Let's have a closer look. Examine `train_labels` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, it's clear that for each observation (or image), train_labels doesn't simply have an output of 1 or 0, but a pair either `[0,1]` or `[1,0]`.\n",
    "\n",
    "Having this information, we still don't know which pair correcponds with `santa` versus `not_santa`. Luckily, what this was stored using `keras.preprocessing_image`, and you can get more info using the command `train_generator.class_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index 0 (the first column) represents `not_santa`, index 1 represents `santa`. Select one of the two columns and transpose the result such that you get a $1$ x $l$ and $1$ x $m$ vector respectively, and value `1` represents `santa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_final = train_labels.T[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(train_labels_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_final = test_labels.T[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(test_labels_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final sanity check, look at an image and the corresponding label, so we're sure that santa is indeed stored as `1`.\n",
    "\n",
    "- First, use `array_to_image` again on the original `train_images` with index 140 to look at this particular image.\n",
    "- Use train_labels_final to get the 240th label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be correct! Feel free to try out other indices as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Lastly, you'll want to standardize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each RGB pixel in an image takes a value between 0 and 255. In Deep Learning, it is very common to standardize and/or center your data set. For images, a common thing that is done is to make sure each pixel value is between 0 and 1. This can be done by dividing the entire matrix by 255. Do this here for the `train_img_unrow` and `test_img_unrow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_final = None\n",
    "test_img_final = None\n",
    "\n",
    "type(test_img_unrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we'll work with `train_img_final`, `test_img_final`, `train_labels_final`, `test_labels_final`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building a logistic regression-based neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Math recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and build our own basic logistic regression-based neural network to disctinguish images with Santa from images without Santa. You've seen in the lecture that logistic regression can actually be represented a a very simple neural network.\n",
    "\n",
    "Remember that we defined that, for each $x^{(i)}$:\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat y ^{(i)}, y^{(i)}) =  - \\big( y^{(i)} \\log(\\hat y^{(i)}) + (1-y^{(i)} )  \\log(1-\\hat y^{(i)})\\big)$$\n",
    "\n",
    "$$\\hat{y}^{(i)} = \\sigma(z^{(i)}) = \\frac{1}{1 + e^{-(z^{(i)})}}$$ \n",
    "\n",
    "$$z^{(i)} = w^T x^{(i)} + b$$\n",
    "\n",
    "The cost function is then given by:\n",
    "$$J(w,b) = \\dfrac{1}{l}\\displaystyle\\sum^l_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this lab, you'll do the following:\n",
    "\n",
    "   - You'll learn how to initialize the parameters of the model\n",
    "   - You'll perform forward propagation, and calculate the current loss\n",
    "   - You'll perform backward propagation (which is basically calculating the current gradient)\n",
    "   - You'll update the parameters (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Parameter initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w$ and $b$ are the unknown parameters to start with. We'll initialize them as 0.\n",
    "- remember that $b$ is a scalar\n",
    "- $w$ however, is a vector of shape $n$ x $1$, with $n$ being `horiz_pixel x vertic_pixel x 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 initialize b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Initialize b as a scalar with value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Initialize w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `init_w(n)` such that when n is filled out, you get a vector with zeros that has a shape $n$ x $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_w(n):\n",
    "    w = None\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call the `init_w` function and set `n` equal to the size of our images, which is `64*64*3` (64 pixels tall x 64 pixels wide x 3 color channels, RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Propagation:\n",
    "- You get `x`\n",
    "- You compute `y_hat`: \n",
    "$$ (\\hat y^{(1)}, \\hat y^{(2)}, \\ldots , \\hat y^{(l)})= \\sigma(w^T x + b) = \\Biggr(\\dfrac{1}{1+exp(w^T x^{(1)}+ b)},\\ldots, \\dfrac{1}{1+exp(w^T x^{(l)}+ b)}\\Biggr) $$\n",
    "- You calculate the `cost` function: $J(w,b) = -\\dfrac{1}{l}\\displaystyle\\sum_{i=1}^{l}y^{(i)}\\log(\\hat y^{(i)})+(1-y^{(i)})\\log(1-\\hat y^{(i)})$\n",
    "\n",
    "Here are the two formulas you will be using to compute the gradients. Don't be scared off by the mathematics. The long formulas are just to show that this corresponds with what we derived in the lectures!\n",
    "\n",
    "$$ \\frac{dJ(w,b)}{dw} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{dw}= \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} x^{(i)} dz^{(i)}  = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} x^{(i)}(\\hat y^{(i)}-y^{(i)})  = \\frac{1}{l}x(\\hat y-y)^T$$\n",
    "\n",
    "$$ \\frac{dJ(w,b)}{db} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{db}= \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} dz^{(i)}  = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} (\\hat y^{(i)}-y^{(i)})$$\n",
    "\n",
    "We've defined this function for you, since it's a bit complex and we haven't deeply covered forward and back propagation yet.  Don't worry, you'll be implementing a more complex version of this from scratch in the next lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagation(w, b, x, y):\n",
    "    l = x.shape[1]\n",
    "    # Get prediction\n",
    "    y_hat = 1/(1 + np.exp(- (np.dot(w.T,x)+b)))       \n",
    "    # Compute cost\n",
    "    cost = -(1/l) * np.sum(y * np.log(y_hat)+(1-y)* np.log(1-y_hat)) \n",
    "    # Get the derivative of weights\n",
    "    dw = (1/l) * np.dot(x,(y_hat-y).T)\n",
    "    db = (1/l) * np.sum(y_hat-y)\n",
    "    return dw, db, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call the function we just wrote to get values for `dw`, `db`, and `cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw, db, cost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dw)\n",
    "\n",
    "print(db)\n",
    "\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in the optimization step, we have to update $w$ and $b$ as follows:\n",
    "\n",
    "$$w := w - \\alpha * dw$$\n",
    "$$b := b - \\alpha * db$$\n",
    "\n",
    "where $\\alpha$ is a scalar value called the **_Learning Rate_**.\n",
    "\n",
    "Note that this `optimization` function also takes in the propagation function. It loops over the `propagation` function in each iteration, and updates both $w$ and $b$ right after that! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(w, b, x, y, num_iterations, learning_rate, print_cost = False):\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        dw, db, cost = None  \n",
    "        w = None\n",
    "        b = None\n",
    "        \n",
    "        # Record the costs and print them every 50 iterations\n",
    "        if i % 50 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 50 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    return w, b, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b, costs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Make label predictions: Santa or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a function that makes label predictions. We'll later use this when we will look at our Santa pictures. What we want, is a label that is equal to 1 when the predicted $y$ is bigger than 0.5, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, b, x):\n",
    "    l = x.shape[1]\n",
    "    y_prediction = np.zeros((1,l))\n",
    "    w = w.reshape(x.shape[0], 1)\n",
    "    y_hat = 1/(1 + np.exp(- (np.dot(w.T,x)+b))) \n",
    "    p = y_hat\n",
    "    \n",
    "    for i in range(y_hat.shape[1]):\n",
    "        if (y_hat[0,i] > 0.5): \n",
    "            y_prediction[0,i] = 1\n",
    "        else:\n",
    "            y_prediction[0,i] = 0\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this out on a small example. Make sure to have 4 predictions in your output here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[0.035],[0.123],[0.217]])\n",
    "b = 0.2\n",
    "x = np.array([[0.2,0.4,-1.2,-2],[1,-2.,0.1,-1],[0.2,0.4,-1.2,-2]])\n",
    "\n",
    "prediction(w,b,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 The overall model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the overall model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "\n",
    "    b = 0\n",
    "    w = init_w(np.shape(x_train)[0]) \n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)--Use the optimization method we just wrote\n",
    "    w, b, costs = None\n",
    "    \n",
    "    # Use the prediction method we wrote to get training and testing predictions\n",
    "    y_pred_test = None\n",
    "    y_pred_train = None\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))\n",
    "\n",
    "    output = {\"costs\": costs,\n",
    "         \"y_pred_test\": y_pred_test, \n",
    "         \"y_pred_train\" : y_pred_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As you can see, this model is fairly complex to build from scratch, but isn't really capable of a complex task like determining if an image contains Santa or not, because this problem is not **_Linearly Separable_**.  This is a problem we can solve by adding more layers and building a **_Multi-Layer Perceptron_** in our next lab--great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
